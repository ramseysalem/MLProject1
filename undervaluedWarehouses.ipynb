{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df6393b1-0c98-4ddc-b476-8b5ff1ad8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting warehouse investment analysis at 2025-04-10 15:45:07\n",
      "================================================================================\n",
      "Step 1: Training investment model on the complete dataset...\n",
      "Loading and preparing warehouse data...\n",
      "Engineering investment features...\n",
      "Creating preprocessing pipeline...\n",
      "Training classification model...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Classification Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        50\n",
      "           1       0.83      1.00      0.91       250\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.42      0.50      0.45       300\n",
      "weighted avg       0.69      0.83      0.76       300\n",
      "\n",
      "\n",
      "Training outlier detector for identifying undervalued properties...\n",
      "\n",
      "Training clustering model for market segmentation...\n",
      "K=3, Silhouette Score: 0.087\n",
      "K=4, Silhouette Score: 0.071\n",
      "K=5, Silhouette Score: 0.070\n",
      "K=6, Silhouette Score: 0.071\n",
      "K=7, Silhouette Score: 0.070\n",
      "Best number of clusters: 3\n",
      "Investment model training complete!\n",
      "Model saved to investment_analysis_results/warehouse_investment_model_20250410_154507.pkl\n",
      "Model trained and saved to investment_analysis_results/warehouse_investment_model_20250410_154507.pkl\n",
      "\n",
      "Step 2: Loading and separating data for analysis...\n",
      "Found 200 properties currently for sale to analyze\n",
      "\n",
      "Step 3: Analyzing all for-sale properties for investment potential...\n",
      "Complete analysis saved to investment_analysis_results/complete_analysis_results_20250410_154507.csv\n",
      "\n",
      "Step 4: Identifying top investment opportunities at different thresholds...\n",
      "Found 1 premium investment opportunities (score >= 90)\n",
      "Found 2 high-quality investment opportunities (score >= 80)\n",
      "Found 3 good investment opportunities (score >= 75)\n",
      "\n",
      "Step 5: Generating investment analysis visualizations...\n",
      "Visualizations saved to investment_analysis_results\n",
      "\n",
      "Step 6: Investment Opportunity Summary:\n",
      "================================================================================\n",
      "Total properties analyzed: 200\n",
      "Properties identified as undervalued: 23 (11.5%)\n",
      "\n",
      "Opportunities by Market Segment:\n",
      "Segment 0.0: 67.0 properties, 3.0 undervalued, avg score: 35.9\n",
      "Segment 1.0: 61.0 properties, 6.0 undervalued, avg score: 38.7\n",
      "Segment 2.0: 72.0 properties, 14.0 undervalued, avg score: 46.6\n",
      "\n",
      "Top 10 Investment Opportunities:\n",
      "   Warehouse Name  Investment Score  Is Undervalued  Estimated Annual ROI (%)  Sale Probability     Location  Cap Rate (%)  Total Price\n",
      "0  Warehouse 1072                90               1                      9.11              0.87  Springfield          8.70     601696.0\n",
      "1  Warehouse 1073                83               1                     11.67              0.86       Newton         11.17    5285196.0\n",
      "2  Warehouse 1014                75               1                      9.97              0.86         Lynn          9.57    4477015.0\n",
      "3  Warehouse 1117                67               0                      5.24              0.91       Boston          5.14    4529721.0\n",
      "4  Warehouse 1064                65               0                     11.64              0.95       Boston         11.42   43350561.0\n",
      "5  Warehouse 1200                65               0                      9.40              0.91  Springfield          9.23   24807986.0\n",
      "6  Warehouse 1131                61               0                     12.10              0.93         Lynn         11.88   37226499.0\n",
      "7  Warehouse 1093                61               0                     12.00              0.82     Brockton         11.78   56478608.0\n",
      "8  Warehouse 1088                60               0                      7.67              0.93         Lynn          7.53    9316695.0\n",
      "9  Warehouse 1009                60               0                     10.30              0.88       Newton         10.12   14395840.0\n",
      "\n",
      "Analysis completed in 11.58 seconds\n",
      "Results saved to investment_analysis_results\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class WarehouseInvestmentModel:\n",
    "    \"\"\"\n",
    "    A specialized model for identifying undervalued warehouse properties with high investment potential.\n",
    "    Focuses on detecting outliers (undervalued properties) that are likely to be sold\n",
    "    and represent strong investment opportunities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the model with feature definitions and empty model containers\"\"\"\n",
    "        # Define feature categories\n",
    "        self.categorical_features = [\n",
    "            \"Location\", \"Warehouse Type\", \"Zoning Regulations\", \"Environmental Concerns\",\n",
    "            \"Neighboring Land Use\", \"Condition of Property\", \"Security Features\", \n",
    "            \"Energy Efficiency Features\"\n",
    "        ]\n",
    "        \n",
    "        self.numerical_features = [\n",
    "            \"Price per SqFt\", \"Total Square Footage\", \"Age of Warehouse\", \"Total Price\",\n",
    "            \"Distance to Highways (miles)\", \"Distance to Ports/Airports (miles)\",\n",
    "            \"NOI\", \"Cap Rate (%)\", \"Year of Last Renovation\", \"Number of Loading Docks\",\n",
    "            \"Clear Height (ft)\", \"Parking and Storage Capacity\"\n",
    "        ]\n",
    "        \n",
    "        # Investment-specific features will be calculated during preprocessing\n",
    "        self.investment_features = [\n",
    "            \"Price_to_NOI_Ratio\", \n",
    "            \"Cap_Rate_to_Avg_Ratio\",\n",
    "            \"Price_per_SqFt_to_Avg_Ratio\",\n",
    "            \"Location_Price_Ratio\",\n",
    "            \"Accessibility_Score\",\n",
    "            \"Modernization_Score\", \n",
    "            \"Value_Index\"\n",
    "        ]\n",
    "        \n",
    "        # Initialize models\n",
    "        self.preprocessor = None\n",
    "        self.classification_model = None\n",
    "        self.outlier_detector = None\n",
    "        self.cluster_model = None\n",
    "        self.location_avg_prices = {}\n",
    "        self.location_avg_cap_rates = {}\n",
    "        self.avg_price_per_sqft = 0\n",
    "        self.avg_cap_rate = 0\n",
    "    \n",
    "    def engineer_investment_features(self, df, training=False):\n",
    "        \"\"\"\n",
    "        Create specialized features to highlight investment value\n",
    "        \n",
    "        Parameters:\n",
    "        df: DataFrame with warehouse data\n",
    "        training: Boolean indicating if this is being used during training\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame with additional investment-focused features\n",
    "        \"\"\"\n",
    "        enhanced_df = df.copy()\n",
    "        \n",
    "        # Calculate basic investment ratios\n",
    "        enhanced_df['Price_to_NOI_Ratio'] = enhanced_df['Total Price'] / enhanced_df['NOI']\n",
    "        \n",
    "        # During training, calculate location-based averages for reference\n",
    "        if training:\n",
    "            # Calculate location averages for price per sqft\n",
    "            self.location_avg_prices = enhanced_df.groupby('Location')['Price per SqFt'].mean().to_dict()\n",
    "            self.location_avg_cap_rates = enhanced_df.groupby('Location')['Cap Rate (%)'].mean().to_dict()\n",
    "            self.avg_price_per_sqft = enhanced_df['Price per SqFt'].mean()\n",
    "            self.avg_cap_rate = enhanced_df['Cap Rate (%)'].mean()\n",
    "        \n",
    "        # Calculate price ratios compared to location averages (lower is better)\n",
    "        enhanced_df['Location_Price_Ratio'] = enhanced_df.apply(\n",
    "            lambda row: row['Price per SqFt'] / self.location_avg_prices.get(row['Location'], self.avg_price_per_sqft), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Calculate cap rate compared to average (higher is better)\n",
    "        enhanced_df['Cap_Rate_to_Avg_Ratio'] = enhanced_df.apply(\n",
    "            lambda row: row['Cap Rate (%)'] / self.location_avg_cap_rates.get(row['Location'], self.avg_cap_rate),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Price per sqft compared to overall average (lower is better)\n",
    "        enhanced_df['Price_per_SqFt_to_Avg_Ratio'] = enhanced_df['Price per SqFt'] / self.avg_price_per_sqft\n",
    "        \n",
    "        # Calculate accessibility score (higher is better)\n",
    "        # Normalize distances so lower distances give higher scores\n",
    "        max_highway_dist = max(enhanced_df['Distance to Highways (miles)'].max(), 15)\n",
    "        max_port_dist = max(enhanced_df['Distance to Ports/Airports (miles)'].max(), 50)\n",
    "        \n",
    "        highway_score = 1 - (enhanced_df['Distance to Highways (miles)'] / max_highway_dist)\n",
    "        port_score = 1 - (enhanced_df['Distance to Ports/Airports (miles)'] / max_port_dist)\n",
    "        \n",
    "        enhanced_df['Accessibility_Score'] = (highway_score * 0.6) + (port_score * 0.4)\n",
    "        \n",
    "        # Calculate modernization score (higher is better)\n",
    "        current_year = 2025\n",
    "        years_since_renovation = current_year - enhanced_df['Year of Last Renovation']\n",
    "        max_years = max(years_since_renovation.max(), 50)  # Cap at 50 years\n",
    "        renovation_score = 1 - (years_since_renovation / max_years)\n",
    "        \n",
    "        # Age score (newer is better)\n",
    "        max_age = max(enhanced_df['Age of Warehouse'].max(), 100)  # Cap at 100 years\n",
    "        age_score = 1 - (enhanced_df['Age of Warehouse'] / max_age)\n",
    "        \n",
    "        enhanced_df['Modernization_Score'] = (renovation_score * 0.6) + (age_score * 0.4)\n",
    "        \n",
    "        # Create value index (higher is better) - key metric for identifying undervalued properties\n",
    "        # Combines multiple factors that indicate good value\n",
    "        enhanced_df['Value_Index'] = (\n",
    "            (1 / enhanced_df['Price_to_NOI_Ratio'].clip(lower=0.01)) * 0.25 +  # Higher NOI relative to price\n",
    "            enhanced_df['Cap_Rate_to_Avg_Ratio'] * 0.25 +                      # Higher cap rate relative to location\n",
    "            (1 / enhanced_df['Location_Price_Ratio'].clip(lower=0.01)) * 0.2 +  # Lower price relative to location\n",
    "            enhanced_df['Accessibility_Score'] * 0.15 +                        # Better accessibility\n",
    "            enhanced_df['Modernization_Score'] * 0.15                          # More modern facility\n",
    "        )\n",
    "        \n",
    "        return enhanced_df\n",
    "    \n",
    "    def create_preprocessor(self):\n",
    "        \"\"\"Create a preprocessing pipeline for the model\"\"\"\n",
    "        # Numerical transformer\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        # Categorical transformer\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "        \n",
    "        # Column transformer\n",
    "        all_numerical_features = self.numerical_features + self.investment_features\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numerical_transformer, all_numerical_features),\n",
    "                ('cat', categorical_transformer, self.categorical_features)\n",
    "            ])\n",
    "        \n",
    "        return preprocessor\n",
    "    \n",
    "    def train(self, data_path):\n",
    "        \"\"\"\n",
    "        Train the complete warehouse investment model\n",
    "        \n",
    "        Parameters:\n",
    "        data_path: Path to the CSV file with warehouse data\n",
    "        \n",
    "        Returns:\n",
    "        Self (for chaining)\n",
    "        \"\"\"\n",
    "        print(\"Loading and preparing warehouse data...\")\n",
    "        warehouse_data = pd.read_csv(data_path)\n",
    "        \n",
    "        # Create target variable (1 for Sold, 0 for For Sale)\n",
    "        y = (warehouse_data[\"Status\"] == \"Sold\").astype(int)\n",
    "        \n",
    "        # Engineer investment-focused features\n",
    "        print(\"Engineering investment features...\")\n",
    "        enhanced_data = self.engineer_investment_features(warehouse_data, training=True)\n",
    "        \n",
    "        # Remove non-feature columns\n",
    "        X = enhanced_data.drop([\"Warehouse Name\", \"Status\"], axis=1)\n",
    "        \n",
    "        # Split data for training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.25, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Create and fit the preprocessor\n",
    "        print(\"Creating preprocessing pipeline...\")\n",
    "        self.preprocessor = self.create_preprocessor()\n",
    "        \n",
    "        # Prepare the classification model\n",
    "        print(\"Training classification model...\")\n",
    "        model_pipeline = Pipeline([\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "        \n",
    "        # Define parameter grid\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [100, 200],\n",
    "            'classifier__max_depth': [None, 15, 25],\n",
    "            'classifier__min_samples_split': [2, 5],\n",
    "            'classifier__class_weight': [None, 'balanced']\n",
    "        }\n",
    "        \n",
    "        # Perform grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            model_pipeline, param_grid, cv=5, \n",
    "            scoring='f1', verbose=1, n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        self.classification_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = self.classification_model.predict(X_test)\n",
    "        y_prob = self.classification_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        print(\"\\nClassification Model Performance:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Train outlier detector to identify undervalued properties\n",
    "        print(\"\\nTraining outlier detector for identifying undervalued properties...\")\n",
    "        \n",
    "        # Prepare investment metrics only for properties that were sold\n",
    "        sold_data = enhanced_data[enhanced_data['Status'] == 'Sold']\n",
    "        sold_X = sold_data.drop([\"Warehouse Name\", \"Status\"], axis=1)\n",
    "        \n",
    "        # Use only relevant investment features for the outlier detection\n",
    "        investment_cols = [\n",
    "            'Price_to_NOI_Ratio', 'Location_Price_Ratio', 'Cap_Rate_to_Avg_Ratio',\n",
    "            'Price_per_SqFt_to_Avg_Ratio', 'Value_Index'\n",
    "        ]\n",
    "        \n",
    "        # Preprocess the investment features\n",
    "        outlier_preprocessor = StandardScaler()\n",
    "        outlier_features = outlier_preprocessor.fit_transform(sold_X[investment_cols])\n",
    "        \n",
    "        # Train Isolation Forest for outlier detection\n",
    "        self.outlier_detector = IsolationForest(\n",
    "            contamination=0.1,  # Assume ~10% of properties are significantly undervalued\n",
    "            random_state=42\n",
    "        )\n",
    "        self.outlier_detector.fit(outlier_features)\n",
    "        \n",
    "        # Train a clustering model to segment properties\n",
    "        print(\"\\nTraining clustering model for market segmentation...\")\n",
    "        \n",
    "        # Preprocess all data for clustering\n",
    "        X_preprocessed = self.preprocessor.fit_transform(X)\n",
    "        \n",
    "        # Find optimal number of clusters using silhouette score\n",
    "        from sklearn.metrics import silhouette_score\n",
    "        \n",
    "        # Try several different cluster counts\n",
    "        k_range = range(3, 8)\n",
    "        silhouette_scores = []\n",
    "        \n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(X_preprocessed)\n",
    "            score = silhouette_score(X_preprocessed, cluster_labels)\n",
    "            silhouette_scores.append(score)\n",
    "            print(f\"K={k}, Silhouette Score: {score:.3f}\")\n",
    "        \n",
    "        # Select the best k\n",
    "        best_k = k_range[np.argmax(silhouette_scores)]\n",
    "        print(f\"Best number of clusters: {best_k}\")\n",
    "        \n",
    "        # Train the final clustering model\n",
    "        self.cluster_model = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "        self.cluster_model.fit(X_preprocessed)\n",
    "        \n",
    "        print(\"Investment model training complete!\")\n",
    "        return self\n",
    "    \n",
    "    def analyze_properties(self, data):\n",
    "        \"\"\"\n",
    "        Analyze properties to identify investment opportunities\n",
    "        \n",
    "        Parameters:\n",
    "        data: DataFrame with warehouse data\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame with analysis results including:\n",
    "          - Sale probability\n",
    "          - Investment opportunity score\n",
    "          - Undervalued flag\n",
    "          - Market segment (cluster)\n",
    "          - Value index\n",
    "        \"\"\"\n",
    "        # Make a copy to avoid modifying the original\n",
    "        data_copy = data.copy()\n",
    "        \n",
    "        # Engineer investment features\n",
    "        enhanced_data = self.engineer_investment_features(data_copy)\n",
    "        \n",
    "        # Remove non-feature columns if present\n",
    "        analysis_data = enhanced_data.copy()\n",
    "        if \"Status\" in analysis_data.columns:\n",
    "            analysis_data = analysis_data.drop(\"Status\", axis=1)\n",
    "        \n",
    "        warehouse_names = analysis_data.get(\"Warehouse Name\", pd.Series([f\"Warehouse_{i}\" for i in range(len(analysis_data))]))\n",
    "        \n",
    "        if \"Warehouse Name\" in analysis_data.columns:\n",
    "            analysis_data = analysis_data.drop(\"Warehouse Name\", axis=1)\n",
    "        \n",
    "        # Make sale probability predictions\n",
    "        sale_probabilities = self.classification_model.predict_proba(analysis_data)[:, 1]\n",
    "        \n",
    "        # Get investment metrics for outlier detection\n",
    "        investment_cols = [\n",
    "            'Price_to_NOI_Ratio', 'Location_Price_Ratio', 'Cap_Rate_to_Avg_Ratio',\n",
    "            'Price_per_SqFt_to_Avg_Ratio', 'Value_Index'\n",
    "        ]\n",
    "        \n",
    "        # Check if these columns exist in the data\n",
    "        for col in investment_cols:\n",
    "            if col not in analysis_data.columns:\n",
    "                raise ValueError(f\"Column {col} is missing from the data. Make sure feature engineering was applied.\")\n",
    "        \n",
    "        # Preprocess investment features\n",
    "        outlier_preprocessor = StandardScaler()\n",
    "        outlier_features = outlier_preprocessor.fit_transform(analysis_data[investment_cols])\n",
    "        \n",
    "        # Detect undervalued properties\n",
    "        # Isolation Forest: -1 for outliers, 1 for inliers, we invert to get 1 for outliers\n",
    "        outlier_scores = -1 * self.outlier_detector.decision_function(outlier_features)\n",
    "        is_undervalued = (self.outlier_detector.predict(outlier_features) == -1).astype(int)\n",
    "        \n",
    "        # Get market segments\n",
    "        X_preprocessed = self.preprocessor.transform(analysis_data)\n",
    "        market_segments = self.cluster_model.predict(X_preprocessed)\n",
    "        \n",
    "        # Calculate investment opportunity score (0-100)\n",
    "        # Combines: sale probability, value index, and outlier score\n",
    "        investment_score = (\n",
    "            sale_probabilities * 0.4 +                                    # Higher probability of being sold\n",
    "            enhanced_data['Value_Index'] / enhanced_data['Value_Index'].max() * 0.4 +  # Higher value index \n",
    "            (outlier_scores - outlier_scores.min()) / \n",
    "            (outlier_scores.max() - outlier_scores.min() + 1e-10) * 0.2   # Higher outlier score (more undervalued)\n",
    "        ) * 100\n",
    "        \n",
    "        # Round scores to integers\n",
    "        investment_score = investment_score.round().astype(int)\n",
    "        \n",
    "        # Calculate estimated annual ROI\n",
    "        # Base ROI is the cap rate, adjusted for undervalued properties and investment score\n",
    "        estimated_roi = enhanced_data['Cap Rate (%)'] * (\n",
    "            1 + (is_undervalued * 0.02) +  # 2% boost for undervalued properties\n",
    "            ((investment_score / 100) * 0.03)  # Up to 3% additional boost based on investment score\n",
    "        )\n",
    "        \n",
    "        # Assign opportunity tier\n",
    "        def assign_tier(score):\n",
    "            if score >= 90:\n",
    "                return 'Premium'\n",
    "            elif score >= 80:\n",
    "                return 'High'\n",
    "            elif score >= 75:\n",
    "                return 'Good'\n",
    "            elif score >= 60:\n",
    "                return 'Fair'\n",
    "            else:\n",
    "                return 'Low'\n",
    "        \n",
    "        opportunity_tiers = [assign_tier(score) for score in investment_score]\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results = pd.DataFrame({\n",
    "            'Warehouse Name': warehouse_names,\n",
    "            'Sale Probability': sale_probabilities.round(3),\n",
    "            'Investment Score': investment_score,\n",
    "            'Opportunity Tier': opportunity_tiers,\n",
    "            'Is Undervalued': is_undervalued,\n",
    "            'Estimated Annual ROI (%)': estimated_roi.round(2),\n",
    "            'Market Segment': market_segments,\n",
    "            'Value Index': enhanced_data['Value_Index'].round(2),\n",
    "            'Price per SqFt': enhanced_data['Price per SqFt'].round(2),\n",
    "            'Cap Rate (%)': enhanced_data['Cap Rate (%)'].round(2),\n",
    "            'Location': enhanced_data['Location'],\n",
    "            'NOI': enhanced_data['NOI'].round(0),\n",
    "            'Total Price': enhanced_data['Total Price'].round(0)\n",
    "        })\n",
    "        \n",
    "        # Sort by investment score (descending)\n",
    "        results = results.sort_values('Investment Score', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_investment_threshold(self, results, threshold=75):\n",
    "        \"\"\"\n",
    "        Analyze results to extract top investment opportunities\n",
    "        \n",
    "        Parameters:\n",
    "        results: DataFrame with analysis results from analyze_properties\n",
    "        threshold: Investment score threshold (default 75)\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame with top investment opportunities\n",
    "        \"\"\"\n",
    "        # Filter for high investment scores\n",
    "        top_investments = results[results['Investment Score'] >= threshold].copy()\n",
    "        \n",
    "        # Top investments should already have all needed columns from analyze_properties\n",
    "        # including 'Opportunity Tier' and 'Estimated Annual ROI (%)'\n",
    "        \n",
    "        return top_investments\n",
    "    \n",
    "    def plot_investment_opportunities(self, results):\n",
    "        \"\"\"Generate visualizations of investment opportunities\"\"\"\n",
    "        # Create a copy to avoid modifying the original\n",
    "        data = results.copy()\n",
    "        \n",
    "        plots = {}\n",
    "        \n",
    "        # 1. Investment score distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=data, x='Investment Score', bins=20, kde=True)\n",
    "        plt.title('Distribution of Investment Opportunity Scores')\n",
    "        plt.xlabel('Investment Score (higher is better)')\n",
    "        plt.ylabel('Count of Properties')\n",
    "        plt.axvline(x=75, color='red', linestyle='--', label='Recommended Threshold (75)')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save to memory\n",
    "        from io import BytesIO\n",
    "        import base64\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png', dpi=100)\n",
    "        buf.seek(0)\n",
    "        plots['score_distribution'] = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Scatter plot of investment score vs. sale probability\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        scatter = sns.scatterplot(\n",
    "            data=data, \n",
    "            x='Sale Probability', \n",
    "            y='Investment Score', \n",
    "            hue='Is Undervalued',\n",
    "            palette={0: 'blue', 1: 'red'},\n",
    "            size='Value Index',\n",
    "            sizes=(20, 200),\n",
    "            alpha=0.7\n",
    "        )\n",
    "        plt.title('Investment Opportunities Matrix')\n",
    "        plt.xlabel('Sale Probability')\n",
    "        plt.ylabel('Investment Score')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add threshold lines\n",
    "        plt.axhline(y=75, color='green', linestyle='--', alpha=0.7, label='Investment Threshold')\n",
    "        plt.axvline(x=0.5, color='orange', linestyle='--', alpha=0.7, label='Sale Probability Threshold')\n",
    "        \n",
    "        # Annotate quadrants\n",
    "        plt.text(0.75, 90, 'PRIME TARGETS', fontsize=12, ha='center', va='center', \n",
    "                bbox=dict(facecolor='green', alpha=0.1, boxstyle='round'))\n",
    "        plt.text(0.25, 90, 'POTENTIAL DEALS\\n(May need negotiations)', fontsize=10, \n",
    "                ha='center', va='center', bbox=dict(facecolor='yellow', alpha=0.1, boxstyle='round'))\n",
    "        plt.text(0.75, 60, 'FAIR VALUE', fontsize=12, ha='center', va='center', \n",
    "                bbox=dict(facecolor='blue', alpha=0.1, boxstyle='round'))\n",
    "        plt.text(0.25, 60, 'LOW INTEREST', fontsize=12, ha='center', va='center', \n",
    "                bbox=dict(facecolor='red', alpha=0.1, boxstyle='round'))\n",
    "        \n",
    "        plt.legend(title='Legend', loc='lower left')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png', dpi=100)\n",
    "        buf.seek(0)\n",
    "        plots['opportunity_matrix'] = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Market segment comparison\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        segment_data = data.groupby('Market Segment').agg({\n",
    "            'Investment Score': 'mean',\n",
    "            'Sale Probability': 'mean',\n",
    "            'Is Undervalued': 'mean',\n",
    "            'Value Index': 'mean',\n",
    "            'Warehouse Name': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        segment_data = segment_data.rename(columns={'Warehouse Name': 'Count'})\n",
    "        \n",
    "        segment_sizes = segment_data['Count'] / segment_data['Count'].sum() * 500\n",
    "        \n",
    "        scatter = sns.scatterplot(\n",
    "            data=segment_data,\n",
    "            x='Sale Probability',\n",
    "            y='Investment Score',\n",
    "            size='Count',\n",
    "            sizes=(100, 500),\n",
    "            hue='Value Index',\n",
    "            palette='viridis',\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Add segment labels\n",
    "        for i, row in segment_data.iterrows():\n",
    "            plt.annotate(f\"Segment {row['Market Segment']}\", \n",
    "                        (row['Sale Probability'], row['Investment Score']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "        \n",
    "        plt.title('Market Segments Comparison')\n",
    "        plt.xlabel('Average Sale Probability')\n",
    "        plt.ylabel('Average Investment Score')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png', dpi=100)\n",
    "        buf.seek(0)\n",
    "        plots['segment_comparison'] = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "        plt.close()\n",
    "        \n",
    "        return plots\n",
    "    \n",
    "    def save(self, filename='warehouse_investment_model.pkl'):\n",
    "        \"\"\"Save the model to a file\"\"\"\n",
    "        joblib.dump(self, filename)\n",
    "        print(f\"Model saved to {filename}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename='warehouse_investment_model.pkl'):\n",
    "        \"\"\"Load a saved model\"\"\"\n",
    "        return joblib.load(filename)\n",
    "\n",
    "\n",
    "# Production usage with the full dataset\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create output directory for results if it doesn't exist\n",
    "    output_dir = \"investment_analysis_results\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Generate timestamp for this analysis run\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(f\"Starting warehouse investment analysis at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create and train the model on the full dataset\n",
    "    print(\"Step 1: Training investment model on the complete dataset...\")\n",
    "    model = WarehouseInvestmentModel()\n",
    "    model.train(\"mock_warehouse_data_large.csv\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_file = os.path.join(output_dir, f\"warehouse_investment_model_{timestamp}.pkl\")\n",
    "    model.save(model_file)\n",
    "    print(f\"Model trained and saved to {model_file}\")\n",
    "    \n",
    "    # Split the dataset: Use 'Sold' properties for training/analysis benchmarks\n",
    "    # and 'For Sale' properties for investment recommendations\n",
    "    print(\"\\nStep 2: Loading and separating data for analysis...\")\n",
    "    full_data = pd.read_csv(\"mock_warehouse_data_large.csv\")\n",
    "    \n",
    "    # Get the 'For Sale' properties - these are our potential investments\n",
    "    for_sale_data = full_data[full_data['Status'] == 'For Sale']\n",
    "    print(f\"Found {len(for_sale_data)} properties currently for sale to analyze\")\n",
    "    \n",
    "    # Get analysis results for all for-sale properties\n",
    "    print(\"\\nStep 3: Analyzing all for-sale properties for investment potential...\")\n",
    "    results = model.analyze_properties(for_sale_data)\n",
    "    \n",
    "    # Save complete analysis results\n",
    "    results_file = os.path.join(output_dir, f\"complete_analysis_results_{timestamp}.csv\")\n",
    "    results.to_csv(results_file, index=False)\n",
    "    print(f\"Complete analysis saved to {results_file}\")\n",
    "    \n",
    "    # Get top investment opportunities at different thresholds\n",
    "    print(\"\\nStep 4: Identifying top investment opportunities at different thresholds...\")\n",
    "    \n",
    "    # Premium opportunities (score >= 90)\n",
    "    premium_investments = model.analyze_investment_threshold(results, threshold=90)\n",
    "    premium_file = os.path.join(output_dir, f\"premium_investment_opportunities_{timestamp}.csv\")\n",
    "    premium_investments.to_csv(premium_file, index=False)\n",
    "    print(f\"Found {len(premium_investments)} premium investment opportunities (score >= 90)\")\n",
    "    \n",
    "    # High-quality opportunities (score >= 80)\n",
    "    high_investments = model.analyze_investment_threshold(results, threshold=80)\n",
    "    high_file = os.path.join(output_dir, f\"high_investment_opportunities_{timestamp}.csv\")\n",
    "    high_investments.to_csv(high_file, index=False)\n",
    "    print(f\"Found {len(high_investments)} high-quality investment opportunities (score >= 80)\")\n",
    "    \n",
    "    # Good opportunities (score >= 75)\n",
    "    good_investments = model.analyze_investment_threshold(results, threshold=75)\n",
    "    good_file = os.path.join(output_dir, f\"good_investment_opportunities_{timestamp}.csv\")\n",
    "    good_investments.to_csv(good_file, index=False)\n",
    "    print(f\"Found {len(good_investments)} good investment opportunities (score >= 75)\")\n",
    "    \n",
    "    # Generate visualizations\n",
    "    print(\"\\nStep 5: Generating investment analysis visualizations...\")\n",
    "    plots = model.plot_investment_opportunities(results)\n",
    "    \n",
    "    # Save plots\n",
    "    for plot_name, plot_data in plots.items():\n",
    "        import base64\n",
    "        img_data = base64.b64decode(plot_data)\n",
    "        \n",
    "        with open(os.path.join(output_dir, f\"{plot_name}_{timestamp}.png\"), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "    \n",
    "    print(f\"Visualizations saved to {output_dir}\")\n",
    "    \n",
    "    # Print summary statistics for investment opportunities\n",
    "    print(\"\\nStep 6: Investment Opportunity Summary:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total properties analyzed: {len(results)}\")\n",
    "    print(f\"Properties identified as undervalued: {results['Is Undervalued'].sum()} ({results['Is Undervalued'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Print distribution by market segment\n",
    "    print(\"\\nOpportunities by Market Segment:\")\n",
    "    segment_stats = results.groupby('Market Segment').agg({\n",
    "        'Investment Score': 'mean',\n",
    "        'Is Undervalued': 'sum',\n",
    "        'Warehouse Name': 'count'\n",
    "    }).reset_index()\n",
    "    segment_stats = segment_stats.rename(columns={'Warehouse Name': 'Count'})\n",
    "    \n",
    "    for _, row in segment_stats.iterrows():\n",
    "        print(f\"Segment {row['Market Segment']}: {row['Count']} properties, {row['Is Undervalued']} undervalued, avg score: {row['Investment Score']:.1f}\")\n",
    "    \n",
    "    # Print top 10 investment opportunities\n",
    "    print(\"\\nTop 10 Investment Opportunities:\")\n",
    "    print(results.head(10)[['Warehouse Name', 'Investment Score', 'Is Undervalued', \n",
    "                          'Estimated Annual ROI (%)', 'Sale Probability', 'Location', \n",
    "                          'Cap Rate (%)', 'Total Price']].to_string())\n",
    "    \n",
    "    # Calculate and print execution time\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"\\nAnalysis completed in {execution_time:.2f} seconds\")\n",
    "    print(f\"Results saved to {output_dir}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399f721-f416-4a0d-8450-c262735c678d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
